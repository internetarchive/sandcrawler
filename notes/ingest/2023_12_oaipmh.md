# OAI-PMH 2023-10 List

We ran two OAI-PMH harvests this year:

* [2023-06-15](https://archive.org/details/oai_harvest_20230615) (279,718,040) (a)
* [2023-11-01](https://archive.org/details/oai_harvest_2023-11-01) (326,163,077) (b)

An increase by 46,445,037. (c)

Out of the first harvest, we created a somewhat deduplicated seed list of
38,362,590 - so about 13%. Given the same ratio holds, we may find about 6M
usable URLs in the the 46M new records.

Instead of the sandcrawler based workflow, we do a CDX check on the starting
URL and keep only the URLs for which we do not have any capture yet.

* [ ] get url list from a
* [ ] get url list from b
* [ ] calculate url list c = b - a
* [ ] run CDX lookup for c
* [ ] keep non-captured list of URLs as seedlist for crawl

Used a subset of URL ("no-id", no .id TLD), for
[a](https://archive.org/download/oai_harvest_20230615/2023-06-15-metha-url-reduced-no-id.txt.zst)
(83,642,625, not 279,718,040).


```shell
$ zstdcat -T0 2023-06-15-metha-url-reduced-no-id.txt.zst | LC_ALL=C sort -T /magna/tmp -S 30% -u | zstd -c -T0 > a.txt.zst
$ zstdcat -T0 2023-11-01-metha-oai-url-uniq.ndjson.zst| LC_ALL=C sort -T /magna/tmp -S 50% -u | zstd -c -T0 > b.txt.zst
$ LC_ALL=C comm -13 <(zstdcat -T0 a.txt.zst) <(zstdcat -T0 b.txt.zst) | pv -l | grep ^http | zstd -c -T0 > c.txt.zst
$ zstdcat -T0 c.txt.zst | grep -v '[.]id/' | zstd -c -T0 > d.txt.zst
```

We end up with 180,622,741 new URLs. Let's exclude ".id" TLD for the moment: 173,388,695 w/o id.

> Taking these 173M URLs and run a CDX server lookup [...]

